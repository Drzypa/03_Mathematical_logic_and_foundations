\documentclass[12pt]{article}
\usepackage{pmmeta}
\pmcanonicalname{51IntroductionToInductiveTypes}
\pmcreated{2013-11-18 2:04:09}
\pmmodified{2013-11-18 2:04:09}
\pmowner{PMBookProject}{1000683}
\pmmodifier{rspuzio}{6075}
\pmtitle{5.1 Introduction to inductive types}
\pmrecord{2}{87674}
\pmprivacy{1}
\pmauthor{PMBookProject}{6075}
\pmtype{Feature}
\pmclassification{msc}{03B15}

\endmetadata

\usepackage{xspace}
\usepackage{amssyb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\makeatletter
\newcommand{\bfalse}{{0_{\bool}}}
\newcommand{\blank}{\mathord{\hspace{1pt}\text{--}\hspace{1pt}}}
\newcommand{\bool}{\ensuremath{\mathbf{2}}\xspace}
\newcommand{\btrue}{{1_{\bool}}}
\newcommand{\cons}{\mathsf{cons}}
\newcommand{\defeq}{\vcentcolon\equiv}  
\newcommand{\define}[1]{\textbf{#1}}
\def\@dprd#1{\prod_{(#1)}\,}
\def\@dprd@noparens#1{\prod_{#1}\,}
\def\@dsm#1{\sum_{(#1)}\,}
\def\@dsm@noparens#1{\sum_{#1}\,}
\def\@eatprd\prd{\prd@parens}
\def\@eatsm\sm{\sm@parens}
\newcommand{\emptyt}{\ensuremath{\mathbf{0}}\xspace}
\newcommand{\id}[3][]{\ensuremath{#2 =_{#1} #3}\xspace}
\newcommand{\ind}[1]{\mathsf{ind}_{#1}}
\newcommand{\indexdef}[1]{\index{#1|defstyle}}   
\newcommand{\indexsee}[2]{\index{#1|see{#2}}}    
\newcommand{\inl}{\ensuremath\inlsym\xspace}
\newcommand{\inlsym}{{\mathsf{inl}}}
\newcommand{\inr}{\ensuremath\inrsym\xspace}
\newcommand{\inrsym}{{\mathsf{inr}}}
\newcommand{\jdeq}{\equiv}      
\newcommand{\lst}[1]{\mathsf{List}(#1)}
\newcommand{\N}{\ensuremath{\mathbb{N}}\xspace}
\newcommand{\nil}{\mathsf{nil}}
\newcommand{\pairr}[1]{{\mathopen{}(#1)\mathclose{}}}
\def\prd#1{\@ifnextchar\bgroup{\prd@parens{#1}}{\@ifnextchar\sm{\prd@parens{#1}\@eatsm}{\prd@noparens{#1}}}}
\def\prd@noparens#1{\mathchoice{\@dprd@noparens{#1}}{\@tprd{#1}}{\@tprd{#1}}{\@tprd{#1}}}
\def\prd@parens#1{\@ifnextchar\bgroup  {\mathchoice{\@dprd{#1}}{\@tprd{#1}}{\@tprd{#1}}{\@tprd{#1}}\prd@parens}  {\@ifnextchar\sm    {\mathchoice{\@dprd{#1}}{\@tprd{#1}}{\@tprd{#1}}{\@tprd{#1}}\@eatsm}    {\mathchoice{\@dprd{#1}}{\@tprd{#1}}{\@tprd{#1}}{\@tprd{#1}}}}}
\def\sm#1{\@ifnextchar\bgroup{\sm@parens{#1}}{\@ifnextchar\prd{\sm@parens{#1}\@eatprd}{\sm@noparens{#1}}}}
\def\sm@noparens#1{\mathchoice{\@dsm@noparens{#1}}{\@tsm{#1}}{\@tsm{#1}}{\@tsm{#1}}}
\def\sm@parens#1{\@ifnextchar\bgroup  {\mathchoice{\@dsm{#1}}{\@tsm{#1}}{\@tsm{#1}}{\@tsm{#1}}\sm@parens}  {\@ifnextchar\prd    {\mathchoice{\@dsm{#1}}{\@tsm{#1}}{\@tsm{#1}}{\@tsm{#1}}\@eatprd}    {\mathchoice{\@dsm{#1}}{\@tsm{#1}}{\@tsm{#1}}{\@tsm{#1}}}}}
\newcommand{\suc}{\mathsf{succ}}
\newcommand{\symlabel}[1]{\refstepcounter{symindex}\label{#1}}
\def\@tprd#1{\mathchoice{{\textstyle\prod_{(#1)}}}{\prod_{(#1)}}{\prod_{(#1)}}{\prod_{(#1)}}}
\def\@tsm#1{\mathchoice{{\textstyle\sum_{(#1)}}}{\sum_{(#1)}}{\sum_{(#1)}}{\sum_{(#1)}}}
\newcommand{\ttt}{\ensuremath{\star}\xspace}
\newcommand{\unit}{\ensuremath{\mathbf{1}}\xspace}
\newcommand{\UU}{\ensuremath{\mathcal{U}}\xspace}
\newcommand{\vcentcolon}{:\!\!}
\newcounter{mathcount}
\setcounter{mathcount}{1}
\newtheorem{prethm}{Theorem}
\newenvironment{thm}{\begin{prethm}}{\end{prethm}\addtocounter{mathcount}{1}}
\renewcommand{\theprethm}{5.1.\arabic{mathcount}}
\let\autoref\cref
\let\nat\N
\let\type\UU
\makeatother

\begin{document}

\index{type!inductive|(}%
\index{generation!of a type, inductive|(}
An \emph{inductive type} $X$ can be intuitively understood as a type ``freely generated'' by a certain finite collection of \emph{constructors}, each of which is a function (of some number of arguments) with codomain $X$.
This includes functions of zero arguments, which are simply elements of $X$.

When describing a particular inductive type, we list the constructors with bullets.
For instance, the type \bool from \PMlinkname{\S 1.8}{18thetypeofbooleans} is inductively generated by the following constructors:
\begin{itemize}
\item $\bfalse:\bool$
\item $\btrue:\bool$
\end{itemize}
Similarly, $\unit$ is inductively generated by the constructor:
\begin{itemize}
\item $\ttt:\unit$
\end{itemize}
while $\emptyt$ is inductively generated by no constructors at all.
An example where the constructor functions take arguments is the coproduct $A+B$, which is generated by the two constructors
\begin{itemize}
\item $\inl:A\to A+B$
\item $\inr:B\to A+B$.
\end{itemize}
And an example with a constructor taking multiple arguments is the cartesian product $A\times B$, which is generated by one constructor
\begin{itemize}
\item $\pairr{\blank, \blank} : A\to B \to A\times B$.
\end{itemize}
Crucially, we also allow constructors of inductive types that take arguments from the inductive type being defined.
For instance, the type $\nat$ of natural numbers has constructors
\begin{itemize}
\item $0:\nat$
\item $\suc:\nat\to\nat$.
\end{itemize}
\symlabel{lst}
\index{type!of lists}%
\indexsee{list}{type of lists}%
Another useful example is the type $\lst A$ of finite lists of elements of some type $A$, which has constructors
\begin{itemize}
\item $\nil:\lst A$
\item $\cons:A\to \lst A \to \lst A$.
\end{itemize}

\index{free!generation of an inductive type}%
Intuitively, we should understand an inductive type as being \emph{freely generated by} its constructors.
That is, the elements of an inductive type are exactly what can be obtained by starting from nothing and applying the constructors repeatedly.
(We will see in \PMlinkname{\S 5.8}{58identitytypesandidentitysystems},\PMlinkexternal{Chapter 6}{http://planetmath.org/node/87579} that this conception has to be modified slightly for more general kinds of inductive definitions, but for now it is sufficient.)
For instance, in the case of \bool, we should expect that the only elements are $\bfalse$ and $\btrue$.
Similarly, in the case of \nat, we should expect that every element is either $0$ or obtained by applying $\suc$ to some ``previously constructed'' natural number.

\index{induction principle}%
Rather than assert properties such as this directly, however, we express them by means of an \emph{induction principle}, also called a \emph{(dependent) elimination rule}.
We have seen these principles already in \PMlinkexternal{Chapter 1}{http://planetmath.org/node/87533}.
For instance, the induction principle for \bool is:
%
\begin{itemize}
\item When proving a statement $E : \bool \to \type$ about \emph{all} inhabitants of \bool, it suffices to prove it for $\bfalse$ and $\btrue$, i.e., to give proofs $e_0 : E(\bfalse)$ and $e_1 : E(\btrue)$.
\end{itemize}

Furthermore, the resulting proof $\ind\bool(E,e_0,e_1): \prd{b : \bool}E(b)$ behaves as expected when applied to the constructors $\bfalse$ and $\btrue$; this principle is expressed by the \emph{computation rules}\index{computation rule!for type of booleans}:
\begin{itemize}
\item We have $\ind\bool(E,e_0,e_1,\bfalse) \jdeq e_0$.
\item We have $\ind\bool(E,e_0,e_1,\btrue) \jdeq e_1$.
\end{itemize}

\index{case analysis}%
Thus, the induction principle for the type $\bool$ of booleans allow us to reason by \emph{case analysis}.
Since neither of the two constructors takes any arguments, this is all we need for booleans.

\index{natural numbers}%
For natural numbers, however, case analysis is generally not sufficient: in the case corresponding to the inductive step $\suc(n)$, we also want to presume that the statement being proven has already been shown for $n$.
This gives us the following induction principle:
\begin{itemize}
\item When proving a statement $E : \nat \to \type$ about \emph{all} natural numbers, it suffices to prove it for $0$ and for $\suc(n)$, assuming it holds
for $n$, i.e., we construct $e_z : E(0)$ and $e_s : \prd{n : \nat}{y : E(n)} E(\suc(n))$.
\end{itemize}
The variable
\index{variable}%
$y$ represents our inductive hypothesis.  As in the case of booleans, we also have the associated computation rules for the function $\ind\nat(E,e_z,e_s) : \prd{x:\nat} E(x)$:
\index{computation rule!for natural numbers}%
\begin{itemize}
\item $\ind\nat(E,e_z,e_s,0) \jdeq e_z$.
\item $\ind\nat(E,e_z,e_s,\suc(n)) \jdeq e_s(n,\ind\nat(E,e_z,e_s,n))$ for any $n : \nat$.
\end{itemize}
The dependent function $\ind\nat(E,e_z,e_s)$ can thus be understood as being defined recursively on the argument $x : \nat$, via the functions $e_z$ and $e_s$ which we call the \define{recurrences}\indexdef{recurrence}.
When $x$ is zero,\index{zero} the function simply returns $e_z$.
When $x$ is the successor\index{successor} of another natural number $n$, the result is obtained by taking the recurrence $e_s$ and substituting the specific predecessor\index{predecessor} $n$ and the recursive call value $\ind\nat(E,e_z,e_s,n)$.

The induction principles for all the examples mentioned above share this family resemblance.
In \PMlinkname{\S 5.6}{56thegeneralsyntaxofinductivedefinitions} we will discuss a general notion of ``inductive definition'' and how to derive an appropriate \emph{induction principle} for it, but first we investigate various commonalities between inductive definitions.

\index{recursion principle}%
For instance, we have remarked in every case in \PMlinkexternal{Chapter 1}{http://planetmath.org/node/87533} that from the induction principle we can derive a \emph{recursion principle} in which the codomain is a simple type (rather than a family).
Both induction and recursion principles may seem odd, since they yield only the \emph{existence} of a function without seeming to characterize it uniquely.
However, in fact the induction principle is strong enough also to prove its own \emph{uniqueness principle}\index{uniqueness!principle, propositional!for functions on N@for functions on $\nat$}, as in the following theorem.

\begin{thm}\label{thm:nat-uniq}
Let $f,g : \prd{x:\nat} E(x)$ be two functions which satisfy the recurrences 
%
\begin{equation*}
  e_z : E(0)
  \qquad\text{and}\qquad
  e_s : \prd{n : \nat}{y : E(n)} E(\suc(n))
\end{equation*}
%
up to propositional equality, i.e., such that
\begin{equation*}
  \id{f(0)}{e_z}
  \qquad\text{and}\qquad
  \id{g(0)}{e_z}
\end{equation*}
as well as
\begin{gather*}
  \prd{n : \nat} \id{f(\suc(n))}{e_s(n, f(n))},\\
  \prd{n : \nat} \id{g(\suc(n))}{e_s(n, g(n))}.
\end{gather*}
Then $f$ and $g$ are equal.
\end{thm}

\begin{proof}
We use induction on the type family $D(x) \defeq \id{f(x)}{g(x)}$. For the base case, we have \[f(0) = e_z = g(0)\]
For the inductive case, assume $n : \nat$ such that $f(n) = g(n)$. Then
\[ f(\suc(n)) = e_s(n, f(n)) = e_s(n, g(n)) = g(\suc(n)) \]
The first and last equality follow from the assumptions on $f$ and $g$. The middle equality follows from the inductive hypothesis and the fact that application preserves equality. This gives us pointwise equality between $f$ and $g$; invoking function extensionality finishes the proof.
\end{proof}

Note that the uniqueness principle applies even to functions that only satisfy the recurrences \emph{up to propositional equality}, i.e.\ a path.
Of course, the particular function obtained from the induction principle satisfies these recurrences judgmentally\index{judgmental equality}; we will return to this point in \PMlinkname{\S 5.5}{55homotopyinductivetypes}.
On the other hand, the theorem itself only asserts a propositional equality between functions (see also \PMlinkexternal{Exercise 5.2}{http://planetmath.org/node/87832}).
From a homotopical viewpoint it is natural to ask whether this path is \emph{coherent}, i.e.\ whether the equality $f=g$ is unique up to higher paths; in \PMlinkname{\S 5.4}{54inductivetypesareinitialalgebras} we will see that this is in fact the case.

Of course, similar uniqueness theorems for functions can generally be formulated and shown for other inductive types as well.
In the next section, we show how this uniqueness property, together with univalence, implies that an inductive type such as the natural numbers is completely characterized by its introduction, elimination, and computation rules.

\index{type!inductive|)}%
\index{generation!of a type, inductive|)}%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}
